<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[TensorFlow学习(三)]]></title>
    <url>%2F2017%2F11%2F08%2FTensorFlow%E5%AD%A6%E4%B9%A0(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[Tensorflow 学习笔记（三）_卷积神经网手写数字识别先借助上一篇实现softmax回归时读入数据和初始化会话 12345678import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets('MNIST_data', one_hot=True)sess = tf.InteractiveSession()x = tf.placeholder(tf.float32, shape=[None, 784])y_ = tf.placeholder(tf.float32, shape=[None, 10]) 构建多层卷积网初始化参数（权重&amp;偏置）由于神经网络每一层都有很多参数，同时模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。为了方便定义两个函数用于初始化。 1234567def weight_variable(shape): initial = tf.truncated_normal(shape,stddev=0.1) return tf.Variable(initial)def bias_variable(shape): inital = tf.constant(0.1,shape=shape) return tf.Variable(inital) 卷积和池化(这一部分不是很懂) TensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。 1234def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') 两层卷积第一层1234567W_conv1 = weight_variable([5,5,1,32])b_conv1 = bias_variable([32])x_image = tf.reshape(x,[-1,28,28,1])h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)h_pool1 = max_pool_2x2(h_conv1) 第二层12345W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2) 全连接层12345W_fc1 = weight_variable([7*7*64,1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1) Dropout(为了防止过拟合) 12keep_prob = tf.placeholder(tf.float32)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) 输出层（采用softmax回归）12345W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])#softmaxy_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) 模型训练和评估训练方式和上一篇softmax的流程是一样的，即现描述图，再执行图，不过采用了更为复杂的权重优化方式AdamOptimizer来最小化损失函数。 123456789101112131415cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))sess.run(tf.global_variables_initializer())for i in range(20000): batch = mnist.train.next_batch(50) if i%100 == 0: train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[0], y_: batch[1], keep_prob: 1.0&#125;) print("step %d, training accuracy %g"%(i, train_accuracy)) train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print("test accuracy %g"%accuracy.eval(feed_dict=&#123; x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)) 结果 运行结果 显示最后识别准确率为99.2% 结论在使用softmax回归进行训练的时候识别率为92%，但速度较快可以接受，不过识别率比较低，在使用了深度学习构建神经网的方法进行训练后，速度大幅下降整个训练过成在我的笔记本上跑了大概一个多小时，这是无法接受的，不过最终的训练识别率达到了99.2%提升十分明显，事实说明进行深度学习还是需要一定的硬件支持。 参考 http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_pros.html]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow学习(二)]]></title>
    <url>%2F2017%2F11%2F08%2FTensorFlow%E5%AD%A6%E4%B9%A0(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[Tensorflow 学习笔记（二）_MNIST手写数字识别下载数据集12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/", one_hot=True) 里面包含有55,000 数据点作为训练集 (mnist.train), 10,000 数据点作为测试集 (mnist.test), 并有 5,000 数据作验证 (mnist.validation).每一张图片包含有28*28个像素点，被读取后，在代码展开成一个长度为784的数组 softmax回归模型实现导入tensorflow初始化一个输入 12import tensorflow as tfx = tf.placeholder(tf.float32,[None,784]) placeholder()生成指定大小的占位符，即它里面的内容是什么不重要，目的是为了能够将读入的数据以合适的大小填入占位符。 初始化权重和偏置 12W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10])) W和b也可以用placeholder()来初始化，但由于它们是变量，在后面的图计算过程中不断迭代更新，所以tensorflow有更好用的表示方法Variable(),它表示一张可修改的张量。注意，W的维度是[784，10]，因为我们想要用784维的图片向量乘以它以得到一个10维的证据值向量，每一位对应不同数字类。b的形状是[10]，所以我们可以直接把它加到输出上面。 构建模型 1y = tf.nn.softmax(tf.matmul(x,W)+b) 训练模型定义评价指标（损失函数） y 是我们预测的概率分布, y’ 是实际的分布 初始化占位符读入，图片真实结果 1y_ = tf.placeholder(tf.float32,[None,10]) 计算损失函数 1cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) 利用tensorflow训练模型，采用tensorflow提供的学习方法最小化损失函数这里采用了梯度下降的方法进行学习，后面可以学到更多优化参数的方法 1train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) 创建会话 开始学习 12345sess = tf.InteractiveSession()tf.global_variables_initializer().run()for i in range(1000): batch_xs,batch_ys = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;) 模型评估 123correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))print (sess.run(accuracy,feed_dict=&#123;x:mnist.test.images, y_: mnist.test.labels&#125;)) 评估预测值与真实值的差距，采用两个向量的距离平均值作为结果注意：评估采用的是整体的平均值即所有图片的平均值，而不是一张对一张的方式，这样有更好的全局结果 参考 http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.htmlhttps://www.tensorflow.org/get_started/mnist/beginners]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow学习(一)]]></title>
    <url>%2F2017%2F11%2F08%2FTensorFlow%E5%AD%A6%E4%B9%A0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[Tensorflow 学习（一）综述TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组.一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话(session) 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象. 图 TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤被描述成一个图. 在执行阶段, 使用会话执行图中的 op. 构建图构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算.Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入. TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了. 1234567891011121314import tensorflow as tf# 创建一个常量 op, 产生一个 1x2 矩阵. 这个 op 被作为一个节点# 加到默认图中.## 构造器的返回值代表该常量 op 的返回值.matrix1 = tf.constant([[3., 3.]])# 创建另外一个常量 op, 产生一个 2x1 矩阵.matrix2 = tf.constant([[2.],[2.]])# 创建一个矩阵乘法 matmul op , 把 'matrix1' 和 'matrix2' 作为输入.# 返回值 'product' 代表矩阵乘法的结果.product = tf.matmul(matrix1, matrix2) 默认图现在有三个节点, 两个 constant() op, 和一个matmul() op. 为了真正进行矩阵相乘运算, 并得到矩阵乘法的 结果, 你必须在会话里启动这个图. 启动图启动图的第一步是创建一个 Session 对象, 如果无任何创建参数, 会话构造器将启动默认图. 123456789101112131415161718# 启动默认图.sess = tf.Session()# 调用 sess 的 'run()' 方法来执行矩阵乘法 op, 传入 'product' 作为该方法的参数. # 上面提到, 'product' 代表了矩阵乘法 op 的输出, 传入它是向方法表明, 我们希望取回# 矩阵乘法 op 的输出.## 整个执行过程是自动化的, 会话负责传递 op 所需的全部输入. op 通常是并发执行的.# # 函数调用 'run(product)' 触发了图中三个 op (两个常量 op 和一个矩阵乘法 op) 的执行.## 返回值 'result' 是一个 numpy `ndarray` 对象.result = sess.run(product)print result# ==&gt; [[ 12.]]# 任务完成, 关闭会话.sess.close() Session 对象在使用完后需要关闭以释放资源. 除了显式调用 close 外, 也可以使用 “with” 代码块 来自动完成关闭动作. 123with tf.Session() as sess: result = sess.run([product]) print result]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch官方教程代码翻译_ClassifyingNames_Charter-Level_RNN]]></title>
    <url>%2F2017%2F11%2F08%2FPytorch%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B%E4%BB%A3%E7%A0%81%E7%BF%BB%E8%AF%91_ClassifyingNames_Charter-Level_RNN%2F</url>
    <content type="text"><![CDATA[Pytorch官方教程代码翻译_ClassifyingNames_Charter-Level_RNN 我们将建立并训练一个基于caharacter-level RNN（个人理解：字符级的RNN模型）来分类单词，该模型将单词当做一串字母读入，在每一轮训练中输出预测结果和隐藏状态，将其以前的隐藏状态提供给下一步。我们将单词属于哪种语言作为最后的预测结果当做输出。 训练数据集采用来自18种语言的姓氏大概有1000多条。预测结果基于名字的拼写方式得出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# coding=utf-8from __future__ import unicode_literals,print_function,divisionfrom io import openimport globimport torchimport unicodedataimport string'''准备数据: 在数据集data/names目录下有18个TXT文件被命名为"[language].txt"，每个文件包含一串名字，每行一个 大多数名字都是罗马字符（但我们仍需要将Unicode转为ASCII码） 我们最终要得到一个将每种语言与其名字相对应的字典列表形式&#123;language:[names...]&#125; 变量 category 和 line （在例子中对应language和name)为以后方便扩展被使用'''def findFiles(path):return glob.glob(path)print(findFiles('data/names/*.txt'))all_letters = string.ascii_letters + " .,;'"n_letters = len(all_letters)#将Unicode转为ASCII码def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn' and c in all_letters )print(unicodeToAscii('Ślusàrski'))#建立category-line字典，每种语言与其名字相对应的字典列表形式&#123;language:[names...]&#125;category_lines = &#123;&#125;all_categories = []#读取文件进行行分割def readLines(filename): lines = open(filename,encoding='utf-8').read().strip().split('\n') return [unicodeToAscii(line) for line in lines]for filename in findFiles('data/names/*.txt'): category = filename.split('/')[-1].split('.')[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = linesn_categories = len(all_categories)'''将名字转为Tensor: 我们需要将已经组织好的名字转为Tensor变量使得GPU和pytorch可以使用 '''def letterToIndex(letter): return all_letters.find((letter))def letterToTensor(letter): tensor = torch.zeros(1,n_letters) tensor[0][letterToIndex(letter)] = 1 return tensordef lineToTensor(line): tensor = torch.zeros(len(line),1,n_letters) for li,letter in enumerate(line): tensor[li][0][letterToIndex(letter)] = 1 return tensorprint (letterToIndex('J'))print (lineToTensor('Jones').size()) 创建网络在自动求导梯度之前，在Torch创建一个RNN网络涉及到]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_image]]></title>
    <url>%2F2017%2F11%2F07%2Ftest_image%2F</url>
    <content type="text"><![CDATA[test_image]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>随记</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb学习笔记（二）]]></title>
    <url>%2F2017%2F11%2F07%2FMongodb%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Mongodb学习笔记（二） 关于Unicode字符串的一点说明你可能已经注意到，之前存入数据库的事常规的Python字符串，这与我们从数据库服务器里取回来的看起来不同（比如 u’Mike’ 而不是‘Mike’）。 下面简单解释一下。 MongoDB 以格式保存数据. BSON 字符串都是 UTF-8编码的， 所以PyMongo必须确保它保存的字符串值包含有效地 UTF-8数据.常规字符串 ( )都是有效的，可以不改变直接保存。Unicode 字符串( )就需要先编码成 UTF-8 格式.例子里的字符串显示为u’Mike’ 而不是 ‘Mike’是因为 PyMongo 会把每个BSON 字符串转换成 Python 的unicode 字符串, 而不是常规的 str. 这个问题困扰了我好多天，其实并不用太担心，因为在python处理过程中它会依然正常处理 Mongodb查询返回值如果用find({})函数查询，则返回的是一个游标并不是字典，类似于list若要查看其中内容需用for循环遍历 123p = StockDB.get_collection('SHistA').find(&#123;&#125;,&#123;ticker:1,"_id":0&#125;)for doc in p: ... 用find_one({})返回的则是字典]]></content>
      <categories>
        <category>Mongodb</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mongodb</tag>
        <tag>pymongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树]]></title>
    <url>%2F2017%2F11%2F07%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[决策树决策树以数据特征做划分，利用特征鲜明且完备的方式将数据划入不同的分类。是一种数值离散的聚类算法。 其中最主要的两个知识点是信息熵和信息增益。决策树根据所给数据特征的信息增益决定划分方式。 特征选择选取对训练数据具有分类功能的特征 信息熵 在信息论和概率统计中对随记变量不确定性的度量 设X是一个取有限个值的离散随机变量，其概率分布： $$P(X = x_i)=p_i, i = 1,2,···n$$ 则X的熵定义为：$H(X) =- \sum_{i=1}^{n}p_ilog(p_i)$log以2为底单位为比特（bit） 上式表明熵越大X的不确定度越大 若有二维随机变量(X,Y），其联合概率为：$$P(X = x_i,Y = yj) = p{ij} ， i = 1,2,3······n,j= 1,2,3······m$$ 条件熵H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定度。$$H(Y|X) = \sum_{i = 1}^{n}p_iH(Y|X=x_i)$$ $$p_i = P(X = x_i),i = 1,2,3······n$$ 在得到一批数据后可以通过数据估计，所得熵与条件熵称经验熵和经验条件熵信息增益表示在得知特征X的条件下，而使得Y的信息不确定性减少的程度。 特征 X对训练数据集Y的信息增益g(Y,X)，定义为集合Y的经验熵H(Y)与特征 X给定条件下Y的经验条件熵H(Y|X)之差$$g(Y,X) = H(Y) - H(Y|X)$$ 因此对给定数据集和特征，信息增益越大的特征具有更强的分类能力 所以特征选择的方法：对数据集，计算其每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征，并迭代进行 计算信息熵（香农熵）12345678910111213141516# 计算信息熵 def CalcShannonEnt(dataSet) : # 计算数据集的输入个数 numEntries=len(dataSet) # []列表,&#123;&#125;元字典,()元组 labelCounts= &#123;&#125; # 创建存储标签的元字典 # 对数据集dataSet中的每一行featVec进行循环遍历 for featVec in dataSet : currentLabels=featVec[-1] # currentLabels为featVec的最后一个元素 if currentLabels not in labelCounts.keys() : # 如果标签currentLabels不在元字典对应的key中 labelCounts[currentLabels]=0 # 将标签currentLabels放到字典中作为key，并将值赋为0 labelCounts[currentLabels]+=1 # 将currentLabels对应的值加1 shannonEnt=0.0 # 定义香农熵shannonEnt for key in labelCounts : # 遍历元字典labelCounts中的key，即标签 prob=float(labelCounts[key]) / numEntries # 计算每一个标签出现的频率，即概率 shannonEnt -=prob * log(prob, 2)# 根据信息熵公式计算每个标签信息熵并累加到shannonEnt上return shannonEnt# 返回求得的整个标签对应的信息熵 计算条件熵选择最好的分类特征123456789101112131415161718def chooseBestFeatureToSplit(dataSet): # 选择使分割后信息增益最大的特征，即对应的列 numFeatures=len(dataSet[0]) - 1 # 获取特征的数目，从0开始，dataSet[0]是一条数据 baseEntropy=CalcShannonEnt(dataSet) # 计算数据集当前的信息熵 bestInfoGain=0.0 # 定义最大的信息增益 bestFeature=-1 # 定义分割后信息增益最大的特征 for i in range(numFeatures):# 遍历特征，即所有的列，计算每一列分割后的信息增益，找出信息增益最大的列 featList=[example[i] for example in dataSet] # 取出第i列特征赋给featList uniqueVals=set(featList) # 将特征对应的值放到一个集合中，使得特征列的数据具有唯一性 newEntropy=0.0 # 定义分割后的信息熵 for value in uniqueVals: # 遍历特征列的所有值(值是唯一的，重复值已经合并)，分割并计算信息增益 subDataSet=splitDataSet(dataSet,i, value) # 按照特征列的每个值进行数据集分割 prob=len(subDataSet) / float(len(dataSet)) # 计算分割后的每个子集的概率(频率) newEntropy+=prob * CalcShannonEnt(subDataSet) # 计算分割后的子集的信息熵并相加，得到分割后的整个数据集的信息熵 infoGain=baseEntropy - newEntropy # 计算分割后的信息增益 if (infoGain &gt; bestInfoGain): #如果分割后信息增益大于最好的信息增益 bestInfoGain=infoGain # 将当前的分割的信息增益赋值为最好信息增益 bestFeature=i # 分割的最好特征列赋为i return bestFeature # 返回分割后信息增益最大的特征列]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 学习笔记（一）]]></title>
    <url>%2F2017%2F11%2F07%2FMongoDB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[MongoDB 学习笔记（一）mongodb是一种非结构化存储数据库，它的数据是以文档为基础的在本地以二进制形式进行存储（Bosn），虽然有与sql查询语句相似的方式，但与SQL语法没有任何关系，更像是一种面相对象的编程，调用函数接口。 启动方式： 1234# apple @ admin [12:05:48] $ mongodb //启动一个mongodb服务器（默认端口在27017）,默认启动连接数据库为 ／data/db 若想指定数据库，需添加参数--dbpath 例： # apple @ admin [12:05:48] $ mongod --dbpath ~/workspace/stock/mongodb/data/db # apple @ admin [12:05:48] $ mongo //启动一个命令行交互程序，是mongodbd的一个进程 我在使用mongodb是主要用python编程进行数据录入和处理，因此使用mongodb提供的pymongo包在程序中连接数据库进行操作 连接数据库： 123from pymongo import MongoClient client=MongoClient() //创建一个服务器进程，默认自动创建端口 db = client['STOCK'] //连接到数据库STOCK 常用数据库操作增：函数名：insert_one() 作用：用于插入一个文档 使用格式：db.get_collection(‘CollectionName’).insert_one({‘key’:’value’}) 函数名：insert_many() 作用：用于插入多个文档 使用格式：db.get_collection(‘CollectionName’).insert_many([ {‘key’: i } ]for i in range(n)) 12345Acoll=db['SEquA'] Aresult=Acoll.insert_many( [ &#123; "ticker": SA['ticker'][i], "secShortName": SA['secShortName'][i]&#125;for i in range(len(SA))]) 查：函数名：find() 作用：查找所需要的文档 使用格式：db.get_collection(‘CollectionName’).find({‘key’:’value’}) 其他使用方式查看：http://api.mongodb.com/python/current/api/pymongo/collection.html?_ga=1.224606170.1159885722.1489465777#pymongo.collection.Collection.find 1234567ATicker=db.get_collection('SEquA').find( &#123;&#125;, &#123; 'ticker': 1, '_id':0&#125;) 注意：find()函数查找所返回的格式是dict,关于dict对象的操作方式自行查找改：函数名：update() 作用：对指定文档进行更新和添加 使用格式：db.get_collection(‘CollectionName’).update({filter},{operation}, otherparameter…) 12345678910111213db.get_collection("SConC").update( &#123; "c_name": SConC['c_name'][i]&#125;, &#123; "$set": &#123; SConC['code'][i]: &#123; "name": SConC['name'][i] &#125; &#125;&#125;, upsert=True)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mongodb</tag>
        <tag>pymongo</tag>
      </tags>
  </entry>
</search>
