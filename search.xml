<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux下zsh配置]]></title>
    <url>%2F2017%2F11%2F30%2FLinux%E4%B8%8Bzsh%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Linux下zsh配置zsh 是Linux下执行终端时bash的一个替代品，我使用它的主要原因是—颜值高 安装1234#install zshuser@computer:~$ sudo apt-get install zsh#instead bashuser@computer:~$ chsh -s /bin/zsh 配置安装oh-my-zsh1user@computer:~$ curl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh 创建一个新的zsh配置文件1user@computer:~$ cp .oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 进行配置1user@computer:~$ vim ~/.zshrc 这里只介绍主题的修改，更多的主题可以在下面的网址中进行挑选https://github.com/robbyrussell/oh-my-zsh/wiki/themes配置好后关闭terminal重新打开，是不是感觉炫酷了很多]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DL&ML工程实验环境搭建]]></title>
    <url>%2F2017%2F11%2F29%2FDL%26ML%E5%B7%A5%E7%A8%8B%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[DL&amp;ML工程实验环境搭建人工智能的大热让很多人都想了解其中的奥秘，然而也有很多人因为实验环境的搭建而放弃在探索的第一步上，作为一个记录，这篇博客将系统的讲述如何搭建一个较为通用完善的DeepLearning和machinelearning实验开发环境。 系统 Unix&amp;Linux如果你是Mac用户那你可以跳过这一部分直接进入下面的开发环境搭建，如果你还在使用Windows并且有不可替代的理由，那么对不起这篇文章无法对你提供任何帮助，在这里我只推荐一种操作系统Linux最流行的发行版Ubuntu，使用其他Linux版本的读者可以做相应的参考。下面列出的是Ubuntu的官方下载地址：http://cn.ubuntu.com/download/安装方法不再赘述，读者可自行搜索 科学上网思索再三觉得这一部分还是不可或缺的，作为目前技术上较为前沿的领域，很多信息国内还来不及消化，遇到问题也无法及时解决，以及一些外国友人开发的第三方工具或网站无法使用，由于众所周知的原因，我们不得不借助一些工具来获取这些信息。当然，如果你对这方面的兴趣和需求并没有这么强烈，你也可以尝试修改Ubuntu或其他的安装源，使他们通过访问国内的镜像源达到同样的目的，具体方法请搜索其他博客得到帮助。在这里我用到的是SSR（shadowsocksR），shadowsocksR作为shadowsocks的部分升级加入了一些混淆等其他协议，分为Client和Server两部分，本人不推荐自己搭建一整套的vpn服务，相对来说购买成熟的服务可以节省好多时间以及避免一些问题，所以这里只用到ssr客户端，当然如果你对相关技术很感兴趣并有较强的动手能力想自己尝试，可以再去参考其他教程自己搭建科学上网服务。用到的软件可以在这两个下载地址找到:这是ssr的客户程序 ssr可视化配置ssr ssr-gui使用Git下载后进入文件1234#进入目录user@computer:~$ cd electron-ssr-0.1.2/#运行程序user@computer:~/electron-ssr-0.1.2$ ./electron-ssr 运行界面进入shadowsocksr目录下的shadowsocks文件夹点击确认然后在下面的页面中就可以配置你自己的VPN了本机代理一般为1080端口如果你使用Firefox浏览器那么你可以在设置中配置socks代理如果使用Chrome可以下载Chrome插件SwitchyOmega按照指导配置本地代理使用代理我们可以愉快的开始上网了上述的一系列配置已经可以满足我们日常信息查询和访问的需求了，但是当我们在安装一些环境时，如Python的第三方package时，在terminal中运行命令，系统默认直接访问而不经过本地代理会导致下载速度非常慢，所以我们还需要配置在命令行模式下的VPN访问，这也是我记录VPN访问搭建时的重点所在。 12345678910111213141516171819202122# install proxychainsuser@computer:~$ sudo apt-get install proxychains # config proxychainsuser@computer:~$ sudo vim /etc/proxychains.conf [ProxyList]# add proxy here ...# meanwile# defaults set to "tor"socks5 127.0.0.1 1080# testuser@computer:~$ proxychains curl www.google.comroxyChains-3.1 (http://proxychains.sf.net)|DNS-request| www.google.com |S-chain|-&lt;&gt;-127.0.0.1:1080-&lt;&gt;&lt;&gt;-4.2.2.2:53-&lt;&gt;&lt;&gt;-OK|DNS-response| www.google.com is 172.217.24.4|S-chain|-&lt;&gt;-127.0.0.1:1080-&lt;&gt;&lt;&gt;-172.217.24.4:80-&lt;&gt;&lt;&gt;-OK&lt;HTML&gt;&lt;HEAD&gt;&lt;meta http-equiv="content-type" content="text/html;charset=utf-8"&gt;&lt;TITLE&gt;302 Moved&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;&lt;H1&gt;302 Moved&lt;/H1&gt;The document has moved&lt;A HREF="http://www.google.co.jp/?gfe_rd=cr&amp;amp;dcr=0&amp;amp;ei=ceAeWo7sNfSm8wehwrvACg"&gt;here&lt;/A&gt;.&lt;/BODY&gt;&lt;/HTML&gt; 之后在使用命令行访问网络时在要执行的命令前加上proxychains 就可以实现代理。 语言环境由于AI在算法方面迭代更新非常频繁，新的方法出现很快，使得我们不能太过于关注一门编程语言的语法细节，因此为了快速开发和容易理解的需求，Python不失为一个较好的选择。如果你之前已经了解和学习过Python恭喜你可以省去一部分语言学习的时间，如果你并没有接触过Python也不用太过担心，Python因其容易理解的特点如果你有其他编程语言的经验，学习起来也十分轻松。 AnacondaUbuntu系统下已经带有Python的开发编译环境，然而它只是一个通用的开发环境，并没有针对数据科学做一些特定配置，很多第三方的十分重要的用来做数据分析的package需要用户自己手动安装如numpy，pandas，sklearn等。因此我推荐安装Anaconda，一个集成了Python编译，包管理以及一些高效辅助工具如notebook的针对Data Science定制的第三方Python环境。我们可以在它的官方网站下载Anaconda。 Python3 OR Python2由于Python的发展迅猛，所以在广泛使用的Python2的基础上有了一次较为重大的更新Python3，然而由于Python3并没有考虑后向兼容，所以导致了一个问题原有在Python2上开发的一些程序在Python3环境下并不能运行，因此如果你是Python2的用户并且有在Python2上运行维护的代码，建议你慎重考虑是否使用Python3，如果你打算重新开始Python或者以前没有接触过Python个人建议直接从Python3环境开始学习，因为技术毕竟在进步，新版本的一些特性是在考虑了旧版的不足优化而来，同时一些第三方package也有过一段时间后不再维护Python2版本，所以选择Python3是比较理想的。 安装下载好对应的anaconda版本 .sh 文件，在terminal中进入下载目录，进行安装 1234567891011121314151617181920212223user@computer:~$ bash Anaconda3-5.0.1-Linux-x86_64.shWelcome to Anaconda3 5.0.1In order to continue the installation process, please review the licenseagreement.Please, press ENTER to continue&gt;&gt;&gt; #单击enter，阅读许可... ... #一直enter，直到读完许可Do you accept the license terms? [yes|no][no] &gt;&gt;&gt; yes #输入yes同意许可Anaconda3 will now be installed into this location:/home/swapinfo/anaconda3 - Press ENTER to confirm the location - Press CTRL-C to abort the installation - Or specify a different location below[/home/swapinfo/anaconda3] &gt;&gt;&gt; #一般为默认安装路径，单击enter就好... 执行安装Do you wish the installer to prepend the Anaconda3 install locationto PATH in your /home/swapinfo/.bashrc ? [yes|no][no] &gt;&gt;&gt; #如果输入yes 则会在全局使用anaconda环境，如果输入no则在每次使用时需要引用。 实验环境OpenCV如果你对CV（computer version）方向很感兴趣的话，OpenCV是你必不可少的用来处理和分析图像的工具。 安装依赖12345678910111213user@computer:~$ sudo apt-get install build-essential checkinstall cmake pkg-config yasmuser@computer:~$ sudo apt-get install git gfortranuser@computer:~$ sudo apt-get install libjpeg8-dev libjasper-dev libpng12-devuser@computer:~$ sudo apt-get install libtiff5-devuser@computer:~$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libdc1394-22-devuser@computer:~$ sudo apt-get install libxine2-dev libv4l-devuser@computer:~$ sudo apt-get install libgstreamer0.10-dev libgstreamer-plugins-base0.10-devuser@computer:~$ sudo apt-get install qt5-default libgtk2.0-dev libtbb-devuser@computer:~$ sudo apt-get install libatlas-base-devuser@computer:~$ sudo apt-get install libfaac-dev libmp3lame-dev libtheora-devuser@computer:~$ sudo apt-get install libvorbis-dev libxvidcore-devuser@computer:~$ sudo apt-get install libopencore-amrnb-dev libopencore-amrwb-devuser@computer:~$ sudo apt-get install x264 v4l-utils 1user@computer:~$ sudo apt-get install python2.7-dev python3.5-dev 下载OpenCV12user@computer:~$ git clone https://github.com/opencv/opencv.gituser@computer:~$ git clone https://github.com/opencv/opencv_contrib.git 编辑OpenCV安装配置1234567891011121314151617user@computer:~$ cd opencv/user@computer:~/opencv$ mkdir builduser@computer:~/opencv$ cd builduser@computer:~/opencv/build$ cmake -D CMAKE_INSTALL_PREFIX=/usr/local \ #默认安装路径 -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \ #额外modules -D ENABLE_FAST_MATH=ON \ -D WITH_CUBLAS=ON \ -D BUILD_OPENCV_PYTHON3=ON \ #这里我使用了Anaconda python3 所以开启Python3编译 -D PYTHON3_EXECUTABLE=~/anaconda3/bin/python \ Anaconda python 执行路径 -D PYTHON3_INCLUDE_PATH=~/anaconda3/include/python3.6m \ -D PYTHON3_LIBRARIES=~/anaconda3/lib/python3.6/site-packages \ -D OPENCV_ENABLE_NONFREE=ON \ -D WITH_TBB=ON \ -D WITH_V4L=ON \ -D INSTALL_C_EXAMPLES=OFF \ -D BUILD_SHARED_LIBS=ON \ .. 编译&amp;安装OpenCV123user@computer:~/opencv/build$ make -j4user@computer:~/opencv/build$ sudo make install user@computer:~/opencv/build$ sudo ldconfig 测试安装是否成功12user@computer:~$ pkg-config --modversion opencv3.3.1 动态链接到Anaconda Python环境123456789101112user@computer:~$ cd /usr/local/lib/python3.4/disk-packages/cv2user@computer:/usr/local/lib/python3.4/disk-packages/cv2$ cp cv2.cpython-34m.so ~/anaconda3/lib/python3.6/site-packages/cv2.so # testuser@computer:~$ ipythonPython 3.6.3 |Anaconda, Inc.| (default, Oct 13 2017, 12:02:49) Type 'copyright', 'credits' or 'license' for more informationIPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: import cv2In [2]: # 安装成功 TensorFlow作为当前最为流行的机器学习库之一，TensorFlow有大量开源的实验的代码和十分活跃的社区为其更新提供支持，当你在遇到问题时也可以十分迅速的得到解决，因此在这里我第一个推荐安装的详细请参考TensorFlow官方安装指导由于实验机器带有NVIDIA独立GPU，所以我用下面的命令进行安装1234if use GPUuser@computer:~$ pip install tensorflowif not use GPUuser@computer:~$ pip install tensorflow-gpu]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>DeepLearning</tag>
        <tag>MachineLearning</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文翻译_通过Wikipedia回答开放域问题]]></title>
    <url>%2F2017%2F11%2F19%2F%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91_%E9%80%9A%E8%BF%87Wikipedia%E5%9B%9E%E7%AD%94%E5%BC%80%E6%94%BE%E5%9F%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[arXiv:1704.00051 通过Wikipedia（维基百科）回答开放域问题Danqi Chen∗Computer Science Stanford University Stanford, CA 94305, USA danqi@cs.stanford.edu Adam Fisch, Jason Weston &amp; Antoine Bordes Facebook AI Research 770 Broadway New York, NY 10003, USA {afisch,jase,abordes}@fb.com 摘要该文章提出通过使用Wikipedia（维基百科）作为唯一知识源来处理开放域问题的回答（任何实际问题的答案都是基于Wikipedia的文本中的信息产生）。这种大规模机器阅读的任务结合了文档重构的挑战， （找到相关的文章）和文本的机器理解（确定这些文章的答案）。 我们的方法将基于双重哈希和TF-IDF匹配的搜索组件与经过训练以检测维基百科段落中的答案的多层递归神经网络模型相结合。我们对多个现有QA数据集的实验表明（1）两个模块与现有的同行相比都具有很强的竞争力;（2）利用远程监督的多任务学习方式，是解决这一挑战性任务的有效体系。 1、引言这篇文章认为回答实际问题的方法在于在开放域中使用Wikipedia做为唯一知识源，类似于人们在百科全书中寻找问题的答案。Wikipedia是一个细节信息不断演进的百科全书如果能够恰当的使用该能力可以促进机器智能不断提升。不同于知识库（KBs）例如Freebase(Bollacker et al., 2008)或者DB-Pedia(Auer et al., 2007)尽管它们更容易被计算和处理，但在开放域问题的回答中却显得十分有限（Miller et al.2016），Wikipedia包涵有人们感兴趣的最新的知识。然而它被设计供人类阅读和使用而不是机器。 将Wikipedia文章作为知识源使得QA任务的挑战不仅要处理大规模开放域问题还要使得机器可以理解文本。为了回答任意问题，首先要从超出500万个条目当中抽取极少数与问题相关的文档，然后仔细的阅读它们来生成回答。我们称这项工作为machine reading at scale（MRS）。我们将Wikipedia当做一个文本集并且不依赖它内部的知识图结构。结果表明我们的方法是通用的并且可以被切换到其他的文本集、书籍、甚至是日更新的新闻报纸中。 大规模QA系统，像IBM的DeepQA (Ferrucci et al., 2010)依赖于多个知识源提供回答：除了Wikipedia还有KBs，字典甚至新闻文章、书籍等。结果是这种系统为了回答准确，极度依赖冗余的信息源。使用单一知识源强迫模型能够非常准确的寻找问题的答案，因为其对应的答案信息可能只出现一次。于机器理解子域和创建数据集例如SQuAD (Rajpurkar et al., 2016), CNN/Daily Mail (Hermann et al., 2015) 和CBT (Hill et al., 2016)，一个关键的动机在于研究机器的阅读能力。 然而这些机器理解源通常假设一小段相关文本已经被识别并被嵌入模型当中。这对建立开放域QA系统来说是不实际的。与之形成鲜明对比的是，使用KB或者文件信息检索的方法必须将搜索作为解决方案的一个组成部分。相反，MRS侧重于同时保持机器理解的挑战，这需要深入理解文本，同时保持对大量开放资源搜索的现实限制。 在本文中我们展示了如何用多个现有的QA数据集评估MRS 即要求开放域系统在这些数据集上都有良好的表现。我们开发了DrQA，一个用Wikipedia来回答问题的强大系统。主要的组成部分有：（1）文档检索器（Document Retriever），一个使用双重哈希和TF-IDF，用来匹配问题答案，可以有效返回相关文章子集的模块，还有（2）文本阅读器（Document Reader）一个多层递归神经网络机器理解模型被训练用来检测答案与这些返回的文本之间的跨度。图一给出了DrQA的示例。 我们的实验表明我们的实验表明，文档检索器（Document Retriever）优于内置的维基百科搜索引擎，文档阅读器（Document Reader）在极具竞争力的SQuAD结果排名上达到了最先进水平。最后我们的完整系统使用多个衡量标准进行评估。特别的，通过使用多任务学习和远程监督学习我们在所有数据集上的性能相对于单任务训练均有所提高。 2、相关工作以每年一度的TREC竞赛[1]为背景，开放域QA起初被定义为在非结构化的文本集中寻找答案。随着KBs的发展，从KBs中创造资源如 WebQuestions (Berant et al., 2013) 和 SimpleQuestions (Bordes et al., 2015) based on the Freebase KB (Bollacker et al., 2008) 或 on automatically extracted KBs, e.g.,OpenIE triples and NELL (Fader et al., 2014). 然而KBs有其固有的缺陷（不完整，模式固定）这使得研究人员回到了原始的基于行文本设置问题的答案。 第二个促使人们从新的角度看待该问题在于机器文本理解例如，在阅读一小段故事后可以回答与之有关的问题。得益于近期的深度学习文章如：attention-based and memory-augmented neural networks (Bahdanau et al., 2015; Weston et al., 2015; Graves et al., 2014) 和新版本的训练和评估数据集如 QuizBowl (Iyyer et al., 2014), CNN/Daily Mail based on news articles (Hermann et al., 2015), CBT based on children books (Hill et al., 2016), 或基于Wikipedia的SQuAD (Rajpurkar et al., 2016) 和 WikiReading (Hewlett et al., 2016),这个子领域已经能够被实现。这篇文章的其中一个目标就是测试这些新方法在开放域QA中的表现如何。 使用Wikipedia作为QA知识源在之前已经被提出Ryu et al. (2014) perform open-domain QA using a Wikipedia-based knowledge model.基于不同类型的半结构化知识例如infoboxes, article structure, category structure, 和definitions，他们通过对多个回答匹配模型生成文本内容。相似的Ahn et al. (2004) 也将Wikipedia与其他数据源作为文本来源, 在这种环境下检索其他文本。Buscaldi and Rosso (2006)也从Wikipedia中为QA挖掘知识和回答。不同于使用Wikipedia作为知识源寻找问题的答案，他们聚焦于QA系统返回的答案的正确性，并使用Wikipedia数据库生成一系列模板判断答案是否是所希望的。在我们所做的工作中，如同引言中描述的一样，我们仅仅考虑文本理解，为了专注于大量机器文本阅读的工作（MRs）使用Wikipedia作为唯一的知识源。 通过使用web已经有大量高度开发的全管道QA方法，如QuASE (Sun et al., 2015)所做的，或者将Wikipedia作为数据源，如Microsoft’s AskMSR (Brill et al., 2002), IBM’s DeepQA (Ferrucci et al., 2010) 和YodaQA (Baudiˇ s, 2015; Baudiˇ s andˇSediv` y, 2015)做的一样，后者是开源的，因此可以重现以用于比较的目的。AskMSR是一个基于QA系统的搜索引擎并且依赖于“数据冗余而不是复杂的问题或候选答案的语言分析”，例如，它不在乎我们所做的机器理解。DeepQA是一个非常复杂的系统，并且依赖于文本包涵的非结构信息和像KBs一样的结构化数据，利用数据库或文章本体生成候选答案或者进行有效的投票。YodaQA是一个仿照DeepQA的开源系统，类似于组建网站，尤其在信息抽取，数据库和Wikipedia方面。我们的文本理解任务在使用单一知识源后面临更大的挑战。与这些方法进行比较为性能上限基准提供了一个有用的数据点。 Multitask learning（多任务学习） (Caruana, 1998)和任务迁移在机器学习中有有丰富的历史，例如，using ImageNet in the computer vision community (Huh et al., 2016))同样在NLP中典型的有(Collobert and Weston, 2008)。这几个工作已经尝试组合多个QA训练数据集通过多任务学习来实现(i)任务迁移改善数据集性能(ii)提供一个单一通用的系统，由于不同数据集中数据分布的不同能够回答不同种类的问题。Fader et al. (2014) 使用 WebQuestions, TREC 和 WikiAnswers将四个 KBs做为知识源并且通过多任务学习在后两个数据集上得到提升。Bordes et al. (2015) 将 WebQuestions 和 SimpleQuestions 组合起来利用远程监督学习 使用 Freebase 作为 KB 在两个数据集上均有小量的提升, 尽管在报告中当使用一个数据集训练并用另一个数据集做测试时有较差的表现，这也表明了任务迁移的确是一个很有挑战性的课题，同样的(Kadlec et al., 2016)得出了相似的结论。我们沿着相似的主题，但不是使用KB而是以文档检索和文本阅读理解为背景，取得了积极的结果。 3、 我们的系统： DrQA接下来我们将我们的DrQA系统描述为由两部分组成的MRS：（1）为了找到相关文档的文档检索模块（2）一个机器理解模型，文档阅读器，为了从单个文档或一小部分文档集合中获得答案。 3.1、文档检索如同传统的QA系统，我们首先采用了高效（非机器学习）的文档检索系统缩小我们的搜索范围并且仅专注于阅读可能相关的文档。对于许多问题类型，相比于基于Wikipedia搜索API(GormleyandTong,2015)内建的ElasticSearch，一个简单的倒排索引查找，然后用术语向量模型评分，就可以很好地完成任务。将文章和问题比作TF-IDF模型中的词袋向量中的权重。通过采取n-gram属性和文章词序相结合我们进一步提高了我们的系统。 4、数据5、实验6、结论参考David Ahn, Valentin Jijkoun, Gilad Mishne, Karin Mller, Maarten de Rijke, and Stefan Schlobach. 2004. Using wikipedia at the trec qa track. In Pro- ceedings of TREC 2004. Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives.2007. Dbpedia: A nucleus for a web of open data.In The semantic web, Springer, pages 722–735. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.Neural machine translation by jointly learning toalign andtranslate. InInternational Conference on Learning Representations (ICLR). Petr Baudiˇ s. 2015. YodaQA: a modular question answering system pipeline. In POSTER 2015-19th In-ternational Student Conference on Electrical Engineering. pages 1156–1165. Petr Baudiˇ s and JanˇSediv` y. 2015.Modeling of the question answering task in the YodaQA system.In International Conference of the Cross- Language Evaluation Forum for European Languages. Springer, pages 222–228. Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Empirical Methods in Natural Language Processing (EMNLP). pages 1533–1544. Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data. AcM, pages 1247–1250. Antoine Bordes, Nicolas Usunier, Sumit Chopra, and Jason Weston. 2015. Large-scale simple question answering with memory networks. arXiv preprint arXiv:1506.02075 . Eric Brill, Susan Dumais, and Michele Banko. 2002.An analysis of the Ask MSR question-answering system. In Empirical Methods in Natural Language Processing (EMNLP). pages 257–264. Davide Buscaldi and Paolo Rosso. 2006.Mining knowledge from Wikipedia for the question answering task. In International Conference on Language Resources and Evaluation (LREC). pages 727–730. Rich Caruana. 1998. Multitask learning. In Learning to learn, Springer, pages 95–133. Danqi Chen, Jason Bolton, and Christopher D Man- ning. 2016.A thorough examination of the CNN/Daily Mail reading comprehension task. In Association for Computational Linguistics (ACL). Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In International Conference on Machine Learning (ICML). Anthony Fader, Luke Zettlemoyer, and Oren Etzioni.2014. Open question answering over curated and extracted knowledge bases. In ACM SIGKDD international conference on Knowledge discovery and data mining. pages 1156–1165. David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A Kalyanpur, Adam Lally, J William Murdock, Eric Nyberg, John Prager, et al. 2010. Building Watson: An overview of the DeepQA project. AI magazine 31(3):59–79. Clinton Gormley and Zachary Tong. 2015.Elasticsearch: The Definitive Guide. ” O’Reilly Media, Inc.”. Alex Graves, Greg Wayne, and Ivo Danihelka.2014.Neural turing machines.arXiv preprint arXiv:1410.5401 . Karl Moritz Hermann, Tomáˇ s Koˇ cisk´ y, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. 2015. Teaching machines to read and comprehend. In Advances in Neural Information Processing Systems (NIPS). Daniel Hewlett, Alexandre Lacoste, Llion Jones, Illia Polosukhin, Andrew Fandrianto, Jay Han, Matthew Kelcey, and David Berthelot. 2016. Wikireading: A novel largescale language understanding task over wikipedia. In Association for Computational Linguistics (ACL). pages 1535–1545. Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. 2016. The Goldilocks Principle: Reading children’s books with explicit memory representations. In International Conference on Learning Representations (ICLR). Minyoung Huh, Pulkit Agrawal, and Alexei A Efros.2016.What makes ImageNet good for transfer learning? arXiv preprint arXiv:1608.08614 . Mohit Iyyer, Jordan L Boyd-Graber, Leonardo Max Batista Claudino, Richard Socher, and Hal Daumé III. 2014. A neural network for factoid question answering over paragraphs. In Empirical Methods in Natural Language Processing (EMNLP).pages 633–644. Rudolf Kadlec, Ondrej Bajgar, and Jan Kleindienst.2016. From particular to general: A preliminary case study of transfer learning in reading comprehension. Machine Intelligence Workshop, NIPS . Diederik Kingma and Jimmy Ba. 2014.ఀAdam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 . Kenton Lee, Tom Kwiatkowski, Ankur Parikh, and Dipanjan Das. 2016. Learning recurrent span representations for extractive question answering. arXiv preprint arXiv:1611.01436 . Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J Bethard, and David McClosky. 2014.The stanford corenlp natural language processing toolkit. In Association for Computational Linguistics (ACL). pages 55–60. Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir- Hossein Karimi, Antoine Bordes, and Jason Weston.2016. Key-value memory networks for directly reading documents. In Empirical Methods in Natural Language Processing (EMNLP). pages 1400–1409. Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009.Distant supervision for relation extraction without labeled data.In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL/IJCNLP). pages 1003–1011. Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation.In Empirical Methods in Natural Language Processing (EMNLP). pages 1532–1543. PranavRajpurkar, JianZhang, KonstantinLopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Empirical Methods in Natural Language Processing (EMNLP). Pum-Mo Ryu, MyungGil Jang, and Hyun-Ki Kim.2014.Open domain question answering using Wikipedia-based knowledge model.Information Processing &amp; Management 50(5):683–692. Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2016.Bidirectional attention flow for machine comprehension.arXiv preprint arXiv:1611.01603 . Huan Sun, Hao Ma, Wen-tau Yih, Chen-Tse Tsai, Jingjing Liu, and Ming-Wei Chang. 2015. Open do- main question answering via semantic enrichment.In Proceedings of the 24th International Conference on World Wide Web. ACM, pages 1045–1055. Zhiguo Wang, Haitao Mi, Wael Hamza, and Radu Florian. 2016.Multi-perspective context matching for machine comprehension.arXiv preprint arXiv:1612.04211 . Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola, and Josh Attenberg. 2009.Feature hashing for large scale multitask learning. In International Conference on Machine Learning (ICML).pages 1113–1120. Jason Weston, Sumit Chopra, and Antoine Bordes.2015. Memory networks. In International Conference on Learning Representations (ICLR). Caiming Xiong, Victor Zhong, and Richard Socher.2016. Dynamic coattention networks for question answering. arXiv preprint arXiv:1611.01604 [1] 1http://trec.nist.gov/data/qamain.html]]></content>
      <categories>
        <category>论文翻译</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>torch</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow学习(三)]]></title>
    <url>%2F2017%2F11%2F08%2FTensorFlow%E5%AD%A6%E4%B9%A0(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[Tensorflow 学习笔记（三）_卷积神经网手写数字识别先借助上一篇实现softmax回归时读入数据和初始化会话 12345678import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets('MNIST_data', one_hot=True)sess = tf.InteractiveSession()x = tf.placeholder(tf.float32, shape=[None, 784])y_ = tf.placeholder(tf.float32, shape=[None, 10]) 构建多层卷积网初始化参数（权重&amp;偏置）由于神经网络每一层都有很多参数，同时模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。为了方便定义两个函数用于初始化。 1234567def weight_variable(shape): initial = tf.truncated_normal(shape,stddev=0.1) return tf.Variable(initial)def bias_variable(shape): inital = tf.constant(0.1,shape=shape) return tf.Variable(inital) 卷积和池化(这一部分不是很懂) TensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。 1234def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') 两层卷积第一层1234567W_conv1 = weight_variable([5,5,1,32])b_conv1 = bias_variable([32])x_image = tf.reshape(x,[-1,28,28,1])h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)h_pool1 = max_pool_2x2(h_conv1) 第二层12345W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2) 全连接层12345W_fc1 = weight_variable([7*7*64,1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1) Dropout(为了防止过拟合) 12keep_prob = tf.placeholder(tf.float32)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) 输出层（采用softmax回归）12345W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])#softmaxy_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) 模型训练和评估训练方式和上一篇softmax的流程是一样的，即现描述图，再执行图，不过采用了更为复杂的权重优化方式AdamOptimizer来最小化损失函数。 123456789101112131415cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))sess.run(tf.global_variables_initializer())for i in range(20000): batch = mnist.train.next_batch(50) if i%100 == 0: train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[0], y_: batch[1], keep_prob: 1.0&#125;) print("step %d, training accuracy %g"%(i, train_accuracy)) train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print("test accuracy %g"%accuracy.eval(feed_dict=&#123; x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)) 结果 运行结果 显示最后识别准确率为99.2% 结论在使用softmax回归进行训练的时候识别率为92%，但速度较快可以接受，不过识别率比较低，在使用了深度学习构建神经网的方法进行训练后，速度大幅下降整个训练过成在我的笔记本上跑了大概一个多小时，这是无法接受的，不过最终的训练识别率达到了99.2%提升十分明显，事实说明进行深度学习还是需要一定的硬件支持。 参考 http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_pros.html]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow学习(二)]]></title>
    <url>%2F2017%2F11%2F08%2FTensorFlow%E5%AD%A6%E4%B9%A0(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[Tensorflow 学习笔记（二）_MNIST手写数字识别下载数据集12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/", one_hot=True) 里面包含有55,000 数据点作为训练集 (mnist.train), 10,000 数据点作为测试集 (mnist.test), 并有 5,000 数据作验证 (mnist.validation).每一张图片包含有28*28个像素点，被读取后，在代码展开成一个长度为784的数组 softmax回归模型实现导入tensorflow初始化一个输入 12import tensorflow as tfx = tf.placeholder(tf.float32,[None,784]) placeholder()生成指定大小的占位符，即它里面的内容是什么不重要，目的是为了能够将读入的数据以合适的大小填入占位符。 初始化权重和偏置 12W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10])) W和b也可以用placeholder()来初始化，但由于它们是变量，在后面的图计算过程中不断迭代更新，所以tensorflow有更好用的表示方法Variable(),它表示一张可修改的张量。注意，W的维度是[784，10]，因为我们想要用784维的图片向量乘以它以得到一个10维的证据值向量，每一位对应不同数字类。b的形状是[10]，所以我们可以直接把它加到输出上面。 构建模型 1y = tf.nn.softmax(tf.matmul(x,W)+b) 训练模型定义评价指标（损失函数） y 是我们预测的概率分布, y’ 是实际的分布 初始化占位符读入，图片真实结果 1y_ = tf.placeholder(tf.float32,[None,10]) 计算损失函数 1cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) 利用tensorflow训练模型，采用tensorflow提供的学习方法最小化损失函数这里采用了梯度下降的方法进行学习，后面可以学到更多优化参数的方法 1train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) 创建会话 开始学习 12345sess = tf.InteractiveSession()tf.global_variables_initializer().run()for i in range(1000): batch_xs,batch_ys = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;) 模型评估 123correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))print (sess.run(accuracy,feed_dict=&#123;x:mnist.test.images, y_: mnist.test.labels&#125;)) 评估预测值与真实值的差距，采用两个向量的距离平均值作为结果注意：评估采用的是整体的平均值即所有图片的平均值，而不是一张对一张的方式，这样有更好的全局结果 参考 http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.htmlhttps://www.tensorflow.org/get_started/mnist/beginners]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow学习(一)]]></title>
    <url>%2F2017%2F11%2F08%2FTensorFlow%E5%AD%A6%E4%B9%A0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[Tensorflow 学习（一）综述TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组.一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话(session) 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象. 图 TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤被描述成一个图. 在执行阶段, 使用会话执行图中的 op. 构建图构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算.Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入. TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了. 1234567891011121314import tensorflow as tf# 创建一个常量 op, 产生一个 1x2 矩阵. 这个 op 被作为一个节点# 加到默认图中.## 构造器的返回值代表该常量 op 的返回值.matrix1 = tf.constant([[3., 3.]])# 创建另外一个常量 op, 产生一个 2x1 矩阵.matrix2 = tf.constant([[2.],[2.]])# 创建一个矩阵乘法 matmul op , 把 'matrix1' 和 'matrix2' 作为输入.# 返回值 'product' 代表矩阵乘法的结果.product = tf.matmul(matrix1, matrix2) 默认图现在有三个节点, 两个 constant() op, 和一个matmul() op. 为了真正进行矩阵相乘运算, 并得到矩阵乘法的 结果, 你必须在会话里启动这个图. 启动图启动图的第一步是创建一个 Session 对象, 如果无任何创建参数, 会话构造器将启动默认图. 123456789101112131415161718# 启动默认图.sess = tf.Session()# 调用 sess 的 'run()' 方法来执行矩阵乘法 op, 传入 'product' 作为该方法的参数. # 上面提到, 'product' 代表了矩阵乘法 op 的输出, 传入它是向方法表明, 我们希望取回# 矩阵乘法 op 的输出.## 整个执行过程是自动化的, 会话负责传递 op 所需的全部输入. op 通常是并发执行的.# # 函数调用 'run(product)' 触发了图中三个 op (两个常量 op 和一个矩阵乘法 op) 的执行.## 返回值 'result' 是一个 numpy `ndarray` 对象.result = sess.run(product)print result# ==&gt; [[ 12.]]# 任务完成, 关闭会话.sess.close() Session 对象在使用完后需要关闭以释放资源. 除了显式调用 close 外, 也可以使用 “with” 代码块 来自动完成关闭动作. 123with tf.Session() as sess: result = sess.run([product]) print result]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch官方教程代码翻译_ClassifyingNames_Charter-Level_RNN]]></title>
    <url>%2F2017%2F11%2F08%2FPytorch%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B%E4%BB%A3%E7%A0%81%E7%BF%BB%E8%AF%91_ClassifyingNames_Charter-Level_RNN%2F</url>
    <content type="text"><![CDATA[Pytorch官方教程代码翻译_ClassifyingNames_Charter-Level_RNN 我们将建立并训练一个基于caharacter-level RNN（个人理解：字符级的RNN模型）来分类单词，该模型将单词当做一串字母读入，在每一轮训练中输出预测结果和隐藏状态，将其以前的隐藏状态提供给下一步。我们将单词属于哪种语言作为最后的预测结果当做输出。 训练数据集采用来自18种语言的姓氏大概有1000多条。预测结果基于名字的拼写方式得出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# coding=utf-8from __future__ import unicode_literals,print_function,divisionfrom io import openimport globimport torchimport unicodedataimport string'''准备数据: 在数据集data/names目录下有18个TXT文件被命名为"[language].txt"，每个文件包含一串名字，每行一个 大多数名字都是罗马字符（但我们仍需要将Unicode转为ASCII码） 我们最终要得到一个将每种语言与其名字相对应的字典列表形式&#123;language:[names...]&#125; 变量 category 和 line （在例子中对应language和name)为以后方便扩展被使用'''def findFiles(path):return glob.glob(path)print(findFiles('data/names/*.txt'))all_letters = string.ascii_letters + " .,;'"n_letters = len(all_letters)#将Unicode转为ASCII码def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn' and c in all_letters )print(unicodeToAscii('Ślusàrski'))#建立category-line字典，每种语言与其名字相对应的字典列表形式&#123;language:[names...]&#125;category_lines = &#123;&#125;all_categories = []#读取文件进行行分割def readLines(filename): lines = open(filename,encoding='utf-8').read().strip().split('\n') return [unicodeToAscii(line) for line in lines]for filename in findFiles('data/names/*.txt'): category = filename.split('/')[-1].split('.')[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = linesn_categories = len(all_categories)'''将名字转为Tensor: 我们需要将已经组织好的名字转为Tensor变量使得GPU和pytorch可以使用 '''def letterToIndex(letter): return all_letters.find((letter))def letterToTensor(letter): tensor = torch.zeros(1,n_letters) tensor[0][letterToIndex(letter)] = 1 return tensordef lineToTensor(line): tensor = torch.zeros(len(line),1,n_letters) for li,letter in enumerate(line): tensor[li][0][letterToIndex(letter)] = 1 return tensorprint (letterToIndex('J'))print (lineToTensor('Jones').size()) 创建网络在自动求导梯度之前，在这之前在Torch中创建一个RNN网络涉及到每层参数的拷贝需要消耗部分时间。以前神经层包含的隐藏层和梯度现在全部被计算图自动处理。这意味着你可以以更纯粹的方式搭建RNN网。。。这个RNN模型仅仅采用两个线性层分别处理输入数据和隐藏层，通过LogSoftmax层产生输出。 12345678910111213141516171819202122232425import torch.nn as nnfrom torch.autograd import Variableclass RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(input_size + hidden_size, hidden_size) self.i2o = nn.Linear(input_size + hidden_size, output_size) self.softmax = nn.LogSoftmax() def forward(self, input, hidden): combined = torch.cat((input, hidden), 1) hidden = self.i2h(combined) output = self.i2o(combined) output = self.softmax(output) return output, hidden def initHidden(self): return Variable(torch.zeros(1, self.hidden_size))n_hidden = 128rnn = RNN(n_letters, n_hidden, n_categories) 为了使这个模型可以运行，我们需要传递一个输入（在这个例子中，是当前单词的张量）和之前的隐藏状态（最开始初始化为0）。我们将得到输出（每种语言的可能性）和下个隐藏状态的值（在下一轮训练中使用）。注意：pytorch模型基于Variables而不是直接使用Tensor进行操作 1234input = Variable(letterToTensor('A'))hidden = Variable(torch.zeros(1, n_hidden))output, next_hidden = rnn(input, hidden) 为了更有效的进行计算，我们不想在进行每一步训练时都创建一个新的Tensor，因此我们将使用 lineToTnsor代替letterToTensor并且使用切片。这将会极大的优化Tensor的预计算消耗。 训练训练准备在训练之前我们需要准备几个辅助函数。第一个是用来将网络的输出翻译为]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_image]]></title>
    <url>%2F2017%2F11%2F07%2Ftest_image%2F</url>
    <content type="text"><![CDATA[test_image]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>随记</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb学习笔记（二）]]></title>
    <url>%2F2017%2F11%2F07%2FMongodb%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Mongodb学习笔记（二） 关于Unicode字符串的一点说明你可能已经注意到，之前存入数据库的事常规的Python字符串，这与我们从数据库服务器里取回来的看起来不同（比如 u’Mike’ 而不是‘Mike’）。 下面简单解释一下。 MongoDB 以格式保存数据. BSON 字符串都是 UTF-8编码的， 所以PyMongo必须确保它保存的字符串值包含有效地 UTF-8数据.常规字符串 ( )都是有效的，可以不改变直接保存。Unicode 字符串( )就需要先编码成 UTF-8 格式.例子里的字符串显示为u’Mike’ 而不是 ‘Mike’是因为 PyMongo 会把每个BSON 字符串转换成 Python 的unicode 字符串, 而不是常规的 str. 这个问题困扰了我好多天，其实并不用太担心，因为在python处理过程中它会依然正常处理 Mongodb查询返回值如果用find({})函数查询，则返回的是一个游标并不是字典，类似于list若要查看其中内容需用for循环遍历 123p = StockDB.get_collection('SHistA').find(&#123;&#125;,&#123;ticker:1,"_id":0&#125;)for doc in p: ... 用find_one({})返回的则是字典]]></content>
      <categories>
        <category>Mongodb</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mongodb</tag>
        <tag>pymongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树]]></title>
    <url>%2F2017%2F11%2F07%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[决策树决策树以数据特征做划分，利用特征鲜明且完备的方式将数据划入不同的分类。是一种数值离散的聚类算法。 其中最主要的两个知识点是信息熵和信息增益。决策树根据所给数据特征的信息增益决定划分方式。 特征选择选取对训练数据具有分类功能的特征 信息熵 在信息论和概率统计中对随记变量不确定性的度量 设X是一个取有限个值的离散随机变量，其概率分布： $$P(X = x_i)=p_i, i = 1,2,···n$$ 则X的熵定义为：$H(X) =- \sum_{i=1}^{n}p_ilog(p_i)$log以2为底单位为比特（bit） 上式表明熵越大X的不确定度越大 若有二维随机变量(X,Y），其联合概率为：$$P(X = x_i,Y = yj) = p{ij} ， i = 1,2,3······n,j= 1,2,3······m$$ 条件熵H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定度。$$H(Y|X) = \sum_{i = 1}^{n}p_iH(Y|X=x_i)$$ $$p_i = P(X = x_i),i = 1,2,3······n$$ 在得到一批数据后可以通过数据估计，所得熵与条件熵称经验熵和经验条件熵信息增益表示在得知特征X的条件下，而使得Y的信息不确定性减少的程度。 特征 X对训练数据集Y的信息增益g(Y,X)，定义为集合Y的经验熵H(Y)与特征 X给定条件下Y的经验条件熵H(Y|X)之差$$g(Y,X) = H(Y) - H(Y|X)$$ 因此对给定数据集和特征，信息增益越大的特征具有更强的分类能力 所以特征选择的方法：对数据集，计算其每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征，并迭代进行 计算信息熵（香农熵）12345678910111213141516# 计算信息熵 def CalcShannonEnt(dataSet) : # 计算数据集的输入个数 numEntries=len(dataSet) # []列表,&#123;&#125;元字典,()元组 labelCounts= &#123;&#125; # 创建存储标签的元字典 # 对数据集dataSet中的每一行featVec进行循环遍历 for featVec in dataSet : currentLabels=featVec[-1] # currentLabels为featVec的最后一个元素 if currentLabels not in labelCounts.keys() : # 如果标签currentLabels不在元字典对应的key中 labelCounts[currentLabels]=0 # 将标签currentLabels放到字典中作为key，并将值赋为0 labelCounts[currentLabels]+=1 # 将currentLabels对应的值加1 shannonEnt=0.0 # 定义香农熵shannonEnt for key in labelCounts : # 遍历元字典labelCounts中的key，即标签 prob=float(labelCounts[key]) / numEntries # 计算每一个标签出现的频率，即概率 shannonEnt -=prob * log(prob, 2)# 根据信息熵公式计算每个标签信息熵并累加到shannonEnt上return shannonEnt# 返回求得的整个标签对应的信息熵 计算条件熵选择最好的分类特征123456789101112131415161718def chooseBestFeatureToSplit(dataSet): # 选择使分割后信息增益最大的特征，即对应的列 numFeatures=len(dataSet[0]) - 1 # 获取特征的数目，从0开始，dataSet[0]是一条数据 baseEntropy=CalcShannonEnt(dataSet) # 计算数据集当前的信息熵 bestInfoGain=0.0 # 定义最大的信息增益 bestFeature=-1 # 定义分割后信息增益最大的特征 for i in range(numFeatures):# 遍历特征，即所有的列，计算每一列分割后的信息增益，找出信息增益最大的列 featList=[example[i] for example in dataSet] # 取出第i列特征赋给featList uniqueVals=set(featList) # 将特征对应的值放到一个集合中，使得特征列的数据具有唯一性 newEntropy=0.0 # 定义分割后的信息熵 for value in uniqueVals: # 遍历特征列的所有值(值是唯一的，重复值已经合并)，分割并计算信息增益 subDataSet=splitDataSet(dataSet,i, value) # 按照特征列的每个值进行数据集分割 prob=len(subDataSet) / float(len(dataSet)) # 计算分割后的每个子集的概率(频率) newEntropy+=prob * CalcShannonEnt(subDataSet) # 计算分割后的子集的信息熵并相加，得到分割后的整个数据集的信息熵 infoGain=baseEntropy - newEntropy # 计算分割后的信息增益 if (infoGain &gt; bestInfoGain): #如果分割后信息增益大于最好的信息增益 bestInfoGain=infoGain # 将当前的分割的信息增益赋值为最好信息增益 bestFeature=i # 分割的最好特征列赋为i return bestFeature # 返回分割后信息增益最大的特征列]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 学习笔记（一）]]></title>
    <url>%2F2017%2F11%2F07%2FMongoDB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[MongoDB 学习笔记（一）mongodb是一种非结构化存储数据库，它的数据是以文档为基础的在本地以二进制形式进行存储（Bosn），虽然有与sql查询语句相似的方式，但与SQL语法没有任何关系，更像是一种面相对象的编程，调用函数接口。 启动方式： 1234# apple @ admin [12:05:48] $ mongodb //启动一个mongodb服务器（默认端口在27017）,默认启动连接数据库为 ／data/db 若想指定数据库，需添加参数--dbpath 例： # apple @ admin [12:05:48] $ mongod --dbpath ~/workspace/stock/mongodb/data/db # apple @ admin [12:05:48] $ mongo //启动一个命令行交互程序，是mongodbd的一个进程 我在使用mongodb是主要用python编程进行数据录入和处理，因此使用mongodb提供的pymongo包在程序中连接数据库进行操作 连接数据库： 123from pymongo import MongoClient client=MongoClient() //创建一个服务器进程，默认自动创建端口 db = client['STOCK'] //连接到数据库STOCK 常用数据库操作增：函数名：insert_one() 作用：用于插入一个文档 使用格式：db.get_collection(‘CollectionName’).insert_one({‘key’:’value’}) 函数名：insert_many() 作用：用于插入多个文档 使用格式：db.get_collection(‘CollectionName’).insert_many([ {‘key’: i } ]for i in range(n)) 12345Acoll=db['SEquA'] Aresult=Acoll.insert_many( [ &#123; "ticker": SA['ticker'][i], "secShortName": SA['secShortName'][i]&#125;for i in range(len(SA))]) 查：函数名：find() 作用：查找所需要的文档 使用格式：db.get_collection(‘CollectionName’).find({‘key’:’value’}) 其他使用方式查看：http://api.mongodb.com/python/current/api/pymongo/collection.html?_ga=1.224606170.1159885722.1489465777#pymongo.collection.Collection.find 1234567ATicker=db.get_collection('SEquA').find( &#123;&#125;, &#123; 'ticker': 1, '_id':0&#125;) 注意：find()函数查找所返回的格式是dict,关于dict对象的操作方式自行查找改：函数名：update() 作用：对指定文档进行更新和添加 使用格式：db.get_collection(‘CollectionName’).update({filter},{operation}, otherparameter…) 12345678910111213db.get_collection("SConC").update( &#123; "c_name": SConC['c_name'][i]&#125;, &#123; "$set": &#123; SConC['code'][i]: &#123; "name": SConC['name'][i] &#125; &#125;&#125;, upsert=True)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mongodb</tag>
        <tag>pymongo</tag>
      </tags>
  </entry>
</search>
